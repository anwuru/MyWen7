[JACQUARD dataset](https://jacquard.liris.cnrs.fr/)

> Standford Grasping：10 object，13747 RGB Images，13747 Depth Images
>
> Cornell Grasping：240 object，885 RGB Images，885 Depth Images
>
> YCB Benchmarks：77 object，46200 RGB Images，46200 Depth Images
>
> CMU dataset：150+object，50567 RGB Images
>
> Google dataset：800000 RGB Images
>
> Dex-Net 1.0：150+object，50567 RGB Images
>
> Dex-Net 2.0：150+object，50567 RGB Images
>
> JACQUARD：11619object，54485 RGB Images，108970Depth Images
>
> 抓取路径规划数据集：
>
> 1、Supersizingself-supervision: Learning to grasp from 50k tries and 700 robot hours.
>
> 2、Learning hand-eyecoordination for robotic grasping with deep learning and large-scale datacollection.
>
> 3、Multimodal grasp dataset: A novel visual–tactile data set for robotic manipulation.
>
> 抓取仿真：
>
> 1、Graspit! a versatile simulator for robotic grasping.
>
> 2、Opengrasp: A toolkit for robot grasping simulation.
>
> 3、Deep reinforcement learning for vision-based robotic grasping: Asimulated comparative evaluation of offpolicy methods.
>
> ---
>
> 版权声明：本文为 CSDN 博主「3 Ｄ视觉工坊」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
> 原文链接：https://blog.csdn.net/Yong_Qi2015/article/details/104352197
